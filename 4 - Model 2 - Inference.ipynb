{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T19:15:41.870882Z",
     "start_time": "2020-02-25T19:15:41.462567Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import logging as log\n",
    "import matplotlib.pyplot as plt\n",
    "from openvino.inference_engine import IENetwork, IECore, IEPlugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for working with the Inference Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T19:15:43.000993Z",
     "start_time": "2020-02-25T19:15:42.967944Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    '''\n",
    "    Load and store information for working with the Inference Engine,\n",
    "    and any loaded models.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.plugin = None\n",
    "        self.network = None\n",
    "        self.input_blob = None\n",
    "        self.output_blob = None\n",
    "        self.exec_network = None\n",
    "        self.infer_request = None\n",
    "\n",
    "    def load_model(self, model, device=\"GPU\"):\n",
    "        '''\n",
    "        Load the model given IR files.\n",
    "        Defaults to CPU as device for use in the workspace.\n",
    "        Synchronous requests made within.\n",
    "        '''\n",
    "        model_xml = model\n",
    "        model_bin = os.path.splitext(model_xml)[0] + \".bin\"\n",
    "\n",
    "        # Initialize the plugin\n",
    "        self.plugin = IECore()\n",
    "\n",
    "        # Read the IR as a IENetwork\n",
    "        self.network = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "        # Load the IENetwork into the plugin\n",
    "        self.exec_network = self.plugin.load_network(\n",
    "            self.network, device_name=device)\n",
    "\n",
    "        # Get the input layer\n",
    "        self.input_blob = next(iter(self.network.inputs))\n",
    "        self.output_blob = next(iter(self.network.outputs))\n",
    "\n",
    "        return\n",
    "\n",
    "    def get_input_shape(self):\n",
    "        '''\n",
    "        Gets the input shape of the network\n",
    "        '''\n",
    "        return self.network.inputs[self.input_blob].shape\n",
    "\n",
    "    def async_inference(self, image):\n",
    "        '''\n",
    "        Makes an asynchronous inference request, given an input image.\n",
    "        '''\n",
    "        self.exec_network.start_async(\n",
    "            request_id=0, inputs={self.input_blob: image})\n",
    "        return\n",
    "\n",
    "    def wait(self):\n",
    "        '''\n",
    "        Checks the status of the inference request.\n",
    "        '''\n",
    "        status = self.exec_network.requests[0].wait(-1)\n",
    "        return status\n",
    "\n",
    "    def extract_output(self):\n",
    "        '''\n",
    "        Returns a list of the results for the output layer of the network.\n",
    "        '''\n",
    "        return self.exec_network.requests[0].outputs[self.output_blob]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T17:50:04.551160Z",
     "start_time": "2020-02-21T17:50:04.547649Z"
    }
   },
   "source": [
    "### Initialize the Inference Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T19:15:43.584479Z",
     "start_time": "2020-02-25T19:15:43.581469Z"
    }
   },
   "outputs": [],
   "source": [
    "plugin = Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T17:50:04.866721Z",
     "start_time": "2020-02-21T17:50:04.810783Z"
    }
   },
   "source": [
    "### Load the network model into the IE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T19:15:48.487496Z",
     "start_time": "2020-02-25T19:15:44.206493Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plugin.load_model(\"models/ppn-model-2.xml\", \"HETERO:GPU,CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T17:50:05.043247Z",
     "start_time": "2020-02-21T17:50:05.037264Z"
    }
   },
   "source": [
    "### Check the input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T19:15:48.618535Z",
     "start_time": "2020-02-25T19:15:48.490428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    }
   ],
   "source": [
    "print(plugin.network.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T19:15:48.724543Z",
     "start_time": "2020-02-25T19:15:48.620538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40000, 10]\n"
     ]
    }
   ],
   "source": [
    "net_input_shape = plugin.get_input_shape()\n",
    "print(net_input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T19:15:48.866522Z",
     "start_time": "2020-02-25T19:15:48.730558Z"
    }
   },
   "outputs": [],
   "source": [
    "img_size = 200\n",
    "scale = 0.3\n",
    "z_size = 7\n",
    "pattern_change_speed = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T19:15:49.029492Z",
     "start_time": "2020-02-25T19:15:48.869530Z"
    }
   },
   "outputs": [],
   "source": [
    "def createInputVec(z, x, y):\n",
    "    r = math.sqrt(((x * scale - (img_size * scale / 2))**2) + (\n",
    "        (y * scale - (img_size * scale / 2))**2))\n",
    "    z_size = len(z)\n",
    "    input = np.random.rand(1, z_size + 3)\n",
    "\n",
    "    for i in range(z_size):\n",
    "        input[0][i] = z[i] * scale\n",
    "\n",
    "    input[0][z_size] = x * scale\n",
    "    input[0][z_size + 1] = y * scale\n",
    "    input[0][z_size + 2] = r\n",
    "    return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process output after inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T19:15:49.403619Z",
     "start_time": "2020-02-25T19:15:49.037510Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_and_plot(fps, seconds):\n",
    "\n",
    "    frames = fps * seconds\n",
    "    \n",
    "    z = np.random.rand(z_size)\n",
    "    directions = np.ones(z_size)\n",
    "\n",
    "    for frame in range(frames):\n",
    "\n",
    "        reverse_directions = np.where(np.logical_or(z > 100, z < -100), -1, 1)\n",
    "        directions = directions * reverse_directions\n",
    "        change = np.random.rand(z_size) * pattern_change_speed\n",
    "        z = z + change * directions\n",
    "\n",
    "        input_batch = np.zeros((img_size, img_size, z_size + 3))\n",
    "        for i in range(img_size):\n",
    "\n",
    "            for j in range(img_size):\n",
    "                input_batch[i, j] = createInputVec(z, i, j)\n",
    "\n",
    "        input_batch.resize(img_size * img_size, z_size + 3)\n",
    "\n",
    "        # Perform inference on the input\n",
    "        plugin.async_inference(input_batch)\n",
    "\n",
    "        # Get the output of inference\n",
    "        if plugin.wait() == 0:\n",
    "            output_frame = plugin.extract_output()\n",
    "\n",
    "        output_frame = np.resize(output_frame, (img_size, img_size, 3))\n",
    "        output_frame = (output_frame * 255).astype(np.uint8)\n",
    "        \n",
    "        # displaying each output_frame\n",
    "        imgplot = plt.imshow(output_frame)\n",
    "        plt.show()\n",
    "        \n",
    "        if (frame + 1) % fps == 1:\n",
    "            print(\"\\nSec {:03d}:\".format(int(frame / fps) + 1), end=\" \")\n",
    "        print(\"{:3d}\".format(frame + 1), end=\" \")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
